#!/usr/bin/env python3
"""
uQCme - Microbial Quality Control Web Application

A Streamlit web application for visualizing and exploring microbial QC results
generated by the uQCme CLI tool. This module focuses on data tables and
interactive data exploration, with plotting functionality handled by plot.py.
"""

import os
import streamlit as st
import pandas as pd
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
from plot import QCPlotter, get_available_metrics


class QCDashboard:
    """Main class for the QC dashboard application."""

    def __init__(self, config_path: str):
        """Initialize the dashboard with configuration."""
        self.config = self._load_config(config_path)
        self.data: pd.DataFrame = pd.DataFrame()
        self.mapping: Dict[str, Any] = {}
        self.qc_rules: pd.DataFrame = pd.DataFrame()
        self.qc_tests: pd.DataFrame = pd.DataFrame()
        self.plotter: QCPlotter = QCPlotter(self.config)
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Load configuration from YAML file."""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            st.error(f"Error loading config: {e}")
            st.stop()

    def _get_dashboard_config(self, key: str, default_value):
        """Get dashboard configuration value with fallback to default."""
        dashboard_config = self.config.get('app', {}).get('dashboard', {})
        return dashboard_config.get(key, default_value)

    def load_data(self):
        """Load all required data files."""
        try:
            # Load processed QC results
            data_path = self.config['app']['input']['data']
            self.data = pd.read_csv(data_path, sep='\t')
            
            # Load mapping configuration
            mapping_path = self.config['app']['input']['mapping']
            with open(mapping_path, 'r', encoding='utf-8') as f:
                self.mapping = yaml.safe_load(f)
            
            # Load QC rules
            rules_path = self.config['app']['input']['qc_rules']
            self.qc_rules = pd.read_csv(rules_path, sep='\t')
            
            # Load QC tests
            tests_path = self.config['app']['input']['qc_tests']
            self.qc_tests = pd.read_csv(tests_path, sep='\t')
            
            # Load warnings if available
            warnings_path = self.config['app']['input'].get('warnings')
            if warnings_path and os.path.exists(warnings_path):
                self.warnings = pd.read_csv(warnings_path, sep='\t')
            else:
                self.warnings = None
            
        except Exception as e:
            st.error(f"Error loading data: {e}")
            st.stop()

    def setup_page(self):
        """Set up the Streamlit page configuration."""
        st.set_page_config(
            page_title=self.config.get('title', 'uQCme Dashboard'),
            page_icon="🔬",
            layout="wide",
            initial_sidebar_state="expanded"
        )

    def render_header(self):
        """Render the application header."""
        st.title("🔬 uQCme - Microbial Quality Control Dashboard")
    
    def render_sidebar_metrics(self, filtered_data: pd.DataFrame):
        """Render summary metrics in the sidebar."""
        st.sidebar.subheader("📊 Summary")
        
        # Version info
        version = self.config.get('version', 'Unknown')
        st.sidebar.markdown(f"**Version:** {version}")
        
        # Create columns for horizontal layout
        col1, col2, col3 = st.sidebar.columns(3)
        
        # Sample count metrics (filtered vs total)
        total_samples = len(filtered_data)
        total_all = len(self.data)
        with col1:
            # Show filtered count vs total
            if total_samples == total_all:
                st.metric("Samples", total_samples)
            else:
                delta_text = f"of {total_all}"
                st.metric("Samples", total_samples, delta=delta_text)
        
        st.sidebar.markdown("---")

        # QC outcome metrics (based on filtered data)
        pass_filter = filtered_data['qc_outcome'] == 'PASS'
        pass_count = len(filtered_data[pass_filter])
        
        # Calculate total PASS from unfiltered data
        total_pass_filter = self.data['qc_outcome'] == 'PASS'
        total_pass_count = len(self.data[total_pass_filter])
        
        with col2:
            if pass_count == total_pass_count:
                st.metric("PASS", pass_count)
            else:
                delta_text = f"of {total_pass_count}"
                st.metric("PASS", pass_count, delta=delta_text)
        
        fail_filter = filtered_data['qc_outcome'] != 'PASS'
        fail_count = len(filtered_data[fail_filter])
        
        # Calculate total Issues from unfiltered data
        total_fail_filter = self.data['qc_outcome'] != 'PASS'
        total_fail_count = len(self.data[total_fail_filter])
        
        with col3:
            if fail_count == total_fail_count:
                st.metric("Issues", fail_count)
            else:
                delta_text = f"of {total_fail_count}"
                st.metric("Issues", fail_count, delta=delta_text)

    def _get_filterable_fields(self, data: pd.DataFrame) -> list:
        """Get all fields that should have filters based on mapping config."""
        filterable_fields = []
        sections_columns = self._get_columns_by_section(data)
        
        for section_name, section_cols in sections_columns.items():
            for col_info in section_cols:
                if col_info['filter'] and col_info['column'] in data.columns:
                    filterable_fields.append({
                        'column': col_info['column'],
                        'field_name': col_info['field_name'],
                        'section': section_name
                    })
        
        return filterable_fields

    def _create_numerical_filter(self, filtered_data: pd.DataFrame,
                                 column: str, field_name: str) -> pd.DataFrame:
        """Create and apply numerical range filter."""
        unique_values = filtered_data[column].dropna()
        
        if len(unique_values) == 0:
            return filtered_data
            
        min_val = float(unique_values.min())
        max_val = float(unique_values.max())
        
        # Only show slider if there's a range
        if min_val == max_val:
            return filtered_data
        
        # Check if filters should be reset
        reset_filters = st.session_state.get('filters_reset', False)
        default_value = (min_val, max_val)
        
        # Clear the reset flag after using it
        if reset_filters:
            key = f"range_{column}"
            if key in st.session_state:
                del st.session_state[key]
            
        selected_range = st.sidebar.slider(
            f"{field_name} Range",
            min_value=min_val,
            max_value=max_val,
            value=default_value,
            key=f"range_{column}"
        )
        
        # Apply range filter
        # Include NaN values when slider is at full range
        full_range = (selected_range[0] == min_val and
                      selected_range[1] == max_val)
        if full_range:
            # Full range selected - don't filter anything
            return filtered_data
        else:
            # Partial range - apply filter but preserve NaN
            col_data = filtered_data[column]
            min_check = col_data >= selected_range[0]
            max_check = col_data <= selected_range[1]
            in_range = min_check & max_check
            range_condition = (in_range | col_data.isna())
            return filtered_data[range_condition]

    def _create_categorical_filter(self, filtered_data: pd.DataFrame,
                                   column: str,
                                   field_name: str) -> pd.DataFrame:
        """Create and apply categorical dropdown filter."""
        unique_values = filtered_data[column].dropna()
        
        if len(unique_values) == 0:
            return filtered_data
            
        unique_sorted = sorted(unique_values.unique())
        
        # Only create filter if we have reasonable number of options
        threshold = self._get_dashboard_config(
            'categorical_filter_threshold', 20
        )
        if len(unique_sorted) > threshold:
            return filtered_data
            
        options = ['All'] + list(unique_sorted)
        
        # Check if filters should be reset
        reset_filters = st.session_state.get('filters_reset', False)
        default_index = 0  # 'All'
        
        # Clear the reset flag after using it
        if reset_filters:
            key = f"filter_{column}"
            if key in st.session_state:
                del st.session_state[key]
        
        selected_value = st.sidebar.selectbox(
            f"Filter by {field_name}",
            options,
            index=default_index,
            key=f"filter_{column}"
        )
        
        if selected_value != 'All':
            filter_condition = (filtered_data[column] == selected_value)
            return filtered_data[filter_condition]
        
        return filtered_data

    def _create_text_search_filter(self, filtered_data: pd.DataFrame,
                                   column: str,
                                   field_name: str) -> pd.DataFrame:
        """Create and apply text search filter."""
        # Check if filters should be reset
        reset_filters = st.session_state.get('filters_reset', False)
        default_value = ""
        
        # Clear the reset flag after using it
        if reset_filters:
            key = f"search_{column}"
            if key in st.session_state:
                del st.session_state[key]
        
        search_value = st.sidebar.text_input(
            f"Search {field_name}",
            placeholder=f"Enter {field_name.lower()}...",
            value=default_value,
            key=f"search_{column}"
        )
        
        if search_value:
            column_str = filtered_data[column].astype(str)
            contains_filter = column_str.str.contains(
                search_value, case=False, na=False
            )
            return filtered_data[contains_filter]
        
        return filtered_data

    def _clear_all_filters(self):
        """Clear all filter-related session state values and selections."""
        # Set a reset flag instead of trying to modify widget values directly
        st.session_state['filters_reset'] = True
        
        # Clear sample selections
        if 'selected_samples' in st.session_state:
            st.session_state.selected_samples.clear()
        
        # Force a rerun to refresh the interface
        st.rerun()

    def render_sidebar_filters(self):
        """Render sidebar filters for data exploration."""
        # Get filterable fields from mapping configuration
        filterable_fields = self._get_filterable_fields(self.data)
        
        # Apply filters
        filtered_data = self.data.copy()
        
        # Generate dynamic filters based on mapping configuration
        for field_info in filterable_fields:
            column = field_info['column']
            field_name = field_info['field_name']
            
            if column in filtered_data.columns:
                # Get unique values for this column
                unique_values = filtered_data[column].dropna()
                
                if len(unique_values) > 0:
                    # Check if column is numerical
                    is_numeric = pd.api.types.is_numeric_dtype(unique_values)
                    
                    if is_numeric:
                        # Use extracted numerical filter method
                        filtered_data = self._create_numerical_filter(
                            filtered_data, column, field_name
                        )
                    else:
                        # Categorical or text filters for non-numerical columns
                        unique_sorted = sorted(unique_values.unique())
                        
                        # Determine filter type based on unique count
                        threshold = self._get_dashboard_config(
                            'categorical_filter_threshold', 20
                        )
                        if len(unique_sorted) <= threshold:
                            # Use extracted categorical filter method
                            filtered_data = self._create_categorical_filter(
                                filtered_data, column, field_name
                            )
                        else:
                            # Use extracted text search filter method
                            filtered_data = self._create_text_search_filter(
                                filtered_data, column, field_name
                            )
        
        # Add sample name search (always available)
        # Check if filters should be reset
        reset_filters = st.session_state.get('filters_reset', False)
        default_sample_value = ""
        
        # Clear the reset flag for sample search
        if reset_filters:
            key = "search_sample_name"
            if key in st.session_state:
                del st.session_state[key]
        
        sample_filter = st.sidebar.text_input(
            "Search Sample Names",
            placeholder="Enter sample name...",
            value=default_sample_value,
            key="search_sample_name"
        )
        
        if sample_filter:
            contains_filter = filtered_data['sample_name'].str.contains(
                sample_filter, case=False, na=False
            )
            filtered_data = filtered_data[contains_filter]
        
        # Clear the reset flag after all filters have been processed
        if st.session_state.get('filters_reset', False):
            st.session_state['filters_reset'] = False
        
        # Render summary metrics at the top with filtered data
        self.render_sidebar_metrics(filtered_data)
        
        st.sidebar.header("🔍 Filters")
        
        # Add Clear All Filters button
        if st.sidebar.button("🗑️ Clear All Filters", type="secondary"):
            self._clear_all_filters()
        
        return filtered_data

    def _get_columns_by_section(self, data: pd.DataFrame) -> Dict[str, list]:
        """Get columns organized by section from mapping.yaml."""
        sections_columns = {}
        
        # Get sections from mapping
        sections = self.mapping.get('Sections', {})
        
        for section_name, section_data in sections.items():
            section_cols = []
            
            for field_name, field_config in section_data.items():
                # Skip if field_config is not a dict (e.g., boolean values)
                if not isinstance(field_config, dict):
                    continue
                    
                mapping_key = field_config.get('data', {}).get('mapping')
                if mapping_key and mapping_key in data.columns:
                    # Get report configuration
                    report_config = field_config.get('report', {})
                    
                    # Include hidden fields in the section but mark them
                    is_hidden = (field_config.get('hidden', False) or
                                 report_config.get('hidden', False))
                    
                    section_cols.append({
                        'column': mapping_key,
                        'field_name': field_name,
                        'hidden': is_hidden,
                        'filter': report_config.get('filter', False),
                        'id': report_config.get('id', False)
                    })
            
            if section_cols:  # Only add sections that have columns
                sections_columns[section_name] = section_cols
        
        # Add unmapped columns to "Other" section
        all_mapped_cols = []
        for section_cols in sections_columns.values():
            all_mapped_cols.extend([col['column'] for col in section_cols])
        
        unmapped_cols = [
            col for col in data.columns
            if col not in all_mapped_cols
        ]
        
        if unmapped_cols:
            sections_columns['Other'] = [
                {
                    'column': col,
                    'field_name': col.replace('_', ' ').title(),
                    'hidden': False,
                    'filter': False,
                    'id': False
                }
                for col in unmapped_cols
            ]
        
        return sections_columns

    def _get_id_column(self, data: pd.DataFrame) -> Optional[str]:
        """Get the column marked as ID field in mapping configuration."""
        sections_columns = self._get_columns_by_section(data)
        
        for section_cols in sections_columns.values():
            for col_info in section_cols:
                if col_info.get('id', False):
                    return col_info['column']
        
        return None

    def _get_column_description(self, column_name: str) -> Optional[str]:
        """Get description for a column from mapping configuration."""
        sections = self.mapping.get('Sections', {})
        
        for section_data in sections.values():
            for field_name, field_config in section_data.items():
                # Skip if field_config is not a dict
                if not isinstance(field_config, dict):
                    continue
                    
                mapping_key = field_config.get('data', {}).get('mapping')
                if mapping_key == column_name:
                    # Check for description in report config first
                    report_config = field_config.get('report', {})
                    description = report_config.get('description')
                    if description:
                        return description
                    
                    # Fallback: check QC config for backward compatibility
                    qc_config = field_config.get('QC', {})
                    description = qc_config.get('description')
                    if description:
                        return description
                    
                    # Fallback to field name if no description
                    return field_name
        
        # Return None if no mapping found
        return None

    def _get_priority_colored_columns(self, data: pd.DataFrame) -> list:
        """Get columns that should have priority coloring based on mapping."""
        priority_columns = []
        sections_columns = self._get_columns_by_section(data)
        
        for section_cols in sections_columns.values():
            for col_info in section_cols:
                column_name = col_info['column']
                # Check if this column has priority_coloring enabled
                if (column_name in data.columns and
                        self._column_has_priority_coloring(column_name)):
                    priority_columns.append(column_name)
        
        return priority_columns
    
    def _column_has_priority_coloring(self, column_name: str) -> bool:
        """Check if a column has priority coloring enabled in mapping."""
        sections = self.mapping.get('Sections', {})
        
        for section_data in sections.values():
            for field_config in section_data.values():
                if not isinstance(field_config, dict):
                    continue
                    
                mapping_key = field_config.get('data', {}).get('mapping')
                if mapping_key == column_name:
                    report_config = field_config.get('report', {})
                    return report_config.get('priority_coloring', False)
        
        return False

    def _get_ordered_columns_with_sections(
        self,
        data: pd.DataFrame,
        visible_sections: Dict[str, bool]
    ) -> list:
        """Get ordered columns based on visible sections."""
        ordered_cols = []
        sections_columns = self._get_columns_by_section(data)
        
        # Define section order
        section_order = ['Basic', 'QC_metrics', 'Experimental', 'Other']
        
        # Add columns from visible sections in order
        for section_name in section_order:
            section_visible = visible_sections.get(section_name, True)
            if section_name in sections_columns and section_visible:
                for col_info in sections_columns[section_name]:
                    # Skip hidden fields
                    if col_info['hidden']:
                        continue
                    ordered_cols.append(col_info['column'])
        
        # Add remaining sections not in the predefined order
        for section_name, section_cols in sections_columns.items():
            section_visible = visible_sections.get(section_name, True)
            section_not_ordered = section_name not in section_order
            if section_not_ordered and section_visible:
                for col_info in section_cols:
                    if col_info['column'] not in ordered_cols:
                        ordered_cols.append(col_info['column'])
        
        return ordered_cols

    def _get_qc_outcome_priority(self, outcome: str) -> int:
        """Get priority level for QC outcome."""
        # Get outcome priority mapping from config, with fallback defaults
        config_priorities = self.config.get('outcome_priorities', {})
        
        # Default outcome priority mapping (higher number = higher priority)
        default_priorities = {
            'PASS': 1,
            'WARNING': 2,
            'FAIL': 3,
            'ERROR': 4
        }
        
        # Use config priority if available, otherwise use default
        outcome_upper = outcome.upper()
        if outcome_upper in config_priorities:
            return config_priorities[outcome_upper]
        else:
            return default_priorities.get(outcome_upper, 4)

    def _get_qc_outcome_color(self, outcome: str) -> str:
        """Get color for QC outcome based on priority."""
        priority = self._get_qc_outcome_priority(outcome)
        priority_colors = self.config.get('priority_colors', {})
        
        # Default color mapping as fallback (darker text-friendly colors)
        default_color_mapping = {
            1: "#00AA00",  # Dark green for PASS
            2: "#FF8C00",  # Dark orange for WARNING
            3: "#DC143C",  # Dark red for FAIL
            4: "#8B0000"   # Dark red for ERROR
        }
        
        # Use config color if available, otherwise use default mapping
        if priority in priority_colors:
            return priority_colors[priority]
        else:
            return default_color_mapping.get(priority, "#000000")

    def _get_qc_action_color(self, action: str) -> str:
        """Get color for QC action based on action type."""
        # Map actions to colors
        action_colors = {
            'none': "#00AA00",      # Green for no action needed
            'review': "#FF8C00",    # Orange for review needed
            'reject': "#DC143C",    # Red for reject
            'return_to_lab': "#8B0000"  # Dark red for return to lab
        }
        
        action_lower = action.lower()
        return action_colors.get(action_lower, "#000000")

    def _render_plotly_chart(self, fig, key: str, title: Optional[str] = None):
        """Helper method to render plotly charts with consistent styling."""
        if title:
            st.subheader(title)
        if fig:
            st.plotly_chart(
                fig,
                use_container_width=True,
                key=key
            )

    def _render_styled_dataframe(self, filtered_data: pd.DataFrame,
                                 column_order: list, key: str):
        """Helper method to render dataframe with QC styling and selection."""
        # Initialize session state for selected samples
        if 'selected_samples' not in st.session_state:
            st.session_state.selected_samples = set()
        
        # Get the ID column for sample selection
        id_column = self._get_id_column(filtered_data)
        
        # Create a working copy of the data
        display_data = filtered_data.copy()
        
        # Add selection checkbox column if ID column exists
        if id_column and id_column in filtered_data.columns:
            # Add a checkbox column for selection
            display_data['Select'] = display_data[id_column].apply(
                lambda x: x in st.session_state.selected_samples
            )
            # Put the select column first
            column_order = ['Select'] + column_order
        
        # Configure columns
        column_config = {}
        
        # Configure the select column if present
        if 'Select' in display_data.columns:
            column_config['Select'] = st.column_config.CheckboxColumn(
                "Select",
                help="Select this sample"
            )
        
        # Apply QC styling for columns with priority coloring enabled
        priority_columns = self._get_priority_colored_columns(display_data)
        
        if priority_columns:
            def highlight_priority_values(val, column_name):
                if pd.isna(val):
                    return ''
                
                # For qc_outcome columns, use outcome-based coloring
                if column_name == 'qc_outcome':
                    color = self._get_qc_outcome_color(str(val))
                # For qc_action columns, use action-based coloring
                elif column_name == 'qc_action':
                    color = self._get_qc_action_color(str(val))
                else:
                    # For other priority columns, try to get color by value
                    color = self._get_qc_outcome_color(str(val))
                
                return (f'color: {color}; font-weight: bold; '
                        f'text-shadow: 0 0 3px {color};')
            
            # Apply styling to all priority columns at once
            styled_data = display_data.style
            for column in priority_columns:
                if column in display_data.columns:
                    styled_data = styled_data.map(
                        lambda val, col=column: highlight_priority_values(
                            val, col),
                        subset=[column]
                    )
        else:
            styled_data = display_data
        
        # Disable all columns except Select to prevent accidental editing
        disabled_columns = [col for col in display_data.columns
                            if col != 'Select']
        
        # Use data_editor to enable checkbox interaction
        edited_data = st.data_editor(
            styled_data,
            use_container_width=True,
            key=key,
            column_order=column_order,
            column_config=column_config,
            hide_index=True,
            disabled=disabled_columns
        )
        
        # Update selected samples based on checkbox changes
        if 'Select' in edited_data.columns and id_column:
            # Get current selections from the edited data
            current_selections = set()
            for idx, row in edited_data.iterrows():
                if row['Select']:
                    sample_id = str(row[id_column])
                    current_selections.add(sample_id)
            
            # Update session state if there are changes
            if current_selections != st.session_state.selected_samples:
                st.session_state.selected_samples = current_selections
                st.rerun()
        
        # Display selected samples summary
        if st.session_state.selected_samples:
            selected_samples = sorted(st.session_state.selected_samples)
            selected_text = ', '.join(selected_samples)
            st.info(f"**Selected samples:** {selected_text}")
            
            if st.button("Clear Selection", key=f"clear_{key}"):
                st.session_state.selected_samples.clear()
                st.rerun()

    def render_data_tab(self, filtered_data: pd.DataFrame):
        """Render the data tab with section toggles."""
        st.header("📊 Data")
        
        # Section toggles
        st.subheader("Section Visibility")
        sections_columns = self._get_columns_by_section(filtered_data)
        
        # Create columns for section toggles
        num_columns = self._get_dashboard_config('section_toggle_columns', 3)
        toggle_columns = st.columns(num_columns)
        
        visible_sections = {}
        section_names = list(sections_columns.keys())
        
        # Distribute toggles across columns
        for i, section_name in enumerate(section_names):
            col_idx = i % num_columns
            
            with toggle_columns[col_idx]:
                # Count visible columns in section
                section_cols = sections_columns[section_name]
                visible_col_count = len([
                    col for col in section_cols
                    if not col['hidden']
                ])
                
                # Default visibility based on content
                # Hide sections that are mostly hidden fields or experimental
                default_visible = True
                if visible_col_count == 0:
                    default_visible = False
                
                visible_sections[section_name] = st.checkbox(
                    f"{section_name} ({visible_col_count} columns)",
                    value=default_visible,
                    key=f"data_preview_toggle_{section_name}"
                )
        
        # Get ordered columns based on visible sections for reference
        ordered_columns = self._get_ordered_columns_with_sections(
            filtered_data,
            visible_sections
        )
        
        # Show active sections info
        active_sections = [
            name for name, visible in visible_sections.items()
            if visible
        ]
        
        # Display helpful info about column organization
        if ordered_columns:
            tip_msg = (
                f"💡 **Tip:** Use the column visibility controls (👁️) in the "
                f"table to show/hide specific columns. Currently showing "
                f"{len(ordered_columns)} columns from selected sections: "
                f"{', '.join(active_sections)}"
            )
            st.info(tip_msg)
        
        # Reorder dataframe columns to put important ones first
        # while preserving all columns for eyeball functionality
        priority_columns = []
        other_columns = []
        
        # Add columns in section order priority
        for col in ordered_columns:
            if col in filtered_data.columns:
                priority_columns.append(col)
        
        # Add remaining columns
        for col in filtered_data.columns:
            if col not in priority_columns:
                other_columns.append(col)
        
        # Create column order for Streamlit's column_order parameter
        column_order = priority_columns + other_columns
        
        # Display the dataframe with built-in controls and QC outcome styling
        # Use the full filtered data to ensure column controls are available
        self._render_styled_dataframe(
            filtered_data, column_order, "data_preview_table"
        )
        
        # Show column information organized by visible sections
        with st.expander("📋 Column Information"):
            st.write("**Column mapping from configuration:**")
            
            for section_name in active_sections:
                if section_name in sections_columns:
                    st.subheader(f"{section_name} Section")
                    section_cols = sections_columns[section_name]
                    
                    for col_info in section_cols:
                        mapping_key = col_info['column']
                        field_name = col_info['field_name']
                        hidden = col_info['hidden']
                        has_filter = col_info['filter']
                        is_id = col_info['id']
                        
                        if mapping_key in filtered_data.columns:
                            # Skip hidden fields from display
                            if hidden:
                                continue
                            
                            # Get description from mapping config
                            description = self._get_column_description(
                                mapping_key
                            )
                            
                            # Build display string with additional info
                            extras = []
                            if has_filter:
                                extras.append("Filterable")
                            if is_id:
                                extras.append("ID")
                            
                            extra_info = ""
                            if extras:
                                extra_info = f" ({', '.join(extras)})"
                            
                            # Create field display with description
                            if description and description != field_name:
                                field_display = (
                                    f"- **{field_name}**: `{mapping_key}` - "
                                    f"{description}{extra_info}"
                                )
                            else:
                                field_display = (
                                    f"- **{field_name}**: `{mapping_key}`"
                                    f"{extra_info}"
                                )
                            st.write(field_display)

    def render_overview_tab(self, filtered_data: pd.DataFrame):
        """Render the overview tab with summary statistics."""
        st.header("📈 Overview")
        
        # Use the plotter to create overview charts
        overview_plots = self.plotter.create_quality_overview_dashboard(
            filtered_data
        )
        
        # Display charts in columns
        col1, col2 = st.columns(2)
        
        with col1:
            self._render_plotly_chart(
                overview_plots.get('outcome_pie'),
                "overview_outcome_pie",
                "QC Outcomes Distribution"
            )
        
        with col2:
            self._render_plotly_chart(
                overview_plots.get('species_bar'),
                "overview_species_bar",
                "Species Distribution"
            )
        
        # Failed Rules Analysis
        self._render_plotly_chart(
            overview_plots.get('failed_rules'),
            "overview_failed_rules",
            "Most Common Failed Rules"
        )
        
        # Quality metrics if available
        self._render_plotly_chart(
            overview_plots.get('metric_dist'),
            "overview_metric_dist",
            "Quality Metrics Distribution"
        )
        
        self._render_plotly_chart(
            overview_plots.get('correlation'),
            "overview_correlation",
            "Metrics Correlation"
        )

    def render_quality_metrics_tab(self, filtered_data: pd.DataFrame):
        """Render quality metrics visualizations."""
        st.header("🔍 Quality Metrics")
        
        # Get available numeric columns
        available_cols = get_available_metrics(filtered_data)
        
        if not available_cols:
            warning_msg = (
                "No numeric quality metrics available for visualization."
            )
            st.warning(warning_msg)
            return
        
        # Metrics selection
        col1, col2 = st.columns(2)
        
        with col1:
            selected_metric = st.selectbox(
                "Select Quality Metric",
                available_cols,
                format_func=lambda x: self.plotter._format_column_name(x),
                index=0
            )
        
        with col2:
            chart_type = st.selectbox(
                "Chart Type",
                ["Distribution", "Box Plot", "Scatter Plot"],
                index=0
            )
        
        # Create visualizations using plotter
        if selected_metric and chart_type:
            if chart_type == "Distribution":
                fig = self.plotter.create_distribution_plot(
                    filtered_data, selected_metric
                )
                self._render_plotly_chart(fig, "metrics_distribution")
                
            elif chart_type == "Box Plot":
                fig = self.plotter.create_box_plot(
                    filtered_data, selected_metric
                )
                self._render_plotly_chart(fig, "metrics_box_plot")
                
            elif chart_type == "Scatter Plot":
                # Find another metric for comparison
                other_metrics = [
                    col for col in available_cols
                    if col != selected_metric
                ]
                
                if other_metrics:
                    def format_metric_name(x):
                        return self.plotter._format_column_name(x)
                    
                    y_metric = st.selectbox(
                        "Select Y-axis metric",
                        other_metrics,
                        format_func=format_metric_name,
                        index=0
                    )
                    
                    if y_metric:
                        fig = self.plotter.create_scatter_plot(
                            filtered_data, selected_metric, y_metric
                        )
                        self._render_plotly_chart(fig, "metrics_scatter_plot")
                else:
                    warning_msg = (
                        "No additional metrics available for scatter plot."
                    )
                    st.warning(warning_msg)

    def render_sample_details_tab(self, filtered_data: pd.DataFrame):
        """Render detailed sample information."""
        st.header("🔬 Sample Details")
        
        # Sample selection
        sample_options = filtered_data['sample_name'].tolist()
        
        if not sample_options:
            st.warning("No samples match the current filters.")
            return
        
        selected_sample = st.selectbox(
            "Select Sample (based on filtered data)",
            sample_options
        )
        
        # Get sample data
        selected_filter = filtered_data['sample_name'] == selected_sample
        sample_data = filtered_data[selected_filter].iloc[0]
        
        # Display sample information
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Basic Information")
            st.write(f"**Sample Name:** {sample_data['sample_name']}")
            st.write(f"**Species:** {sample_data['species']}")
            provided_spec = sample_data.get('provided_species', 'N/A')
            st.write(f"**Provided Species:** {provided_spec}")
            st.write(f"**QC Outcome:** {sample_data['qc_outcome']}")
        
        with col2:
            st.subheader("Quality Metrics")
            if 'GC' in sample_data:
                st.write(f"**GC Content:** {sample_data['GC']:.2f}%")
            if 'N50' in sample_data:
                st.write(f"**N50:** {sample_data['N50']:,.0f}")
            if 'bin_length_at_1x' in sample_data:
                genome_size = sample_data['bin_length_at_1x']
                st.write(f"**Genome Size:** {genome_size:,.0f} bp")
        
        # Failed and passed rules
        st.subheader("QC Rules Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            failed_rules_val = sample_data.get('failed_rules')
            if (failed_rules_val and
                    pd.notna(failed_rules_val) and
                    isinstance(failed_rules_val, str)):
                st.write("**Failed Rules:**")
                failed_rules = failed_rules_val.split(',')
                # Display all failed rules, each on one row
                st.write("❌ " + ", ".join([rule.strip() for rule in failed_rules]))
            else:
                st.write("✅ No failed rules")
        
        with col2:
            passed_rules_val = sample_data.get('passed_rules')
            if (passed_rules_val and
                    pd.notna(passed_rules_val) and
                    isinstance(passed_rules_val, str)):
                st.write("**Passed Rules:**")
                passed_rules = passed_rules_val.split(',')
                # Display all passed rules, all on one row
                st.write("✅ " + ", ".join([rule.strip() for rule in passed_rules]))
            else:
                st.write("No passed rules data available")

    def render_qc_tests_tab(self):
        """Render the QC tests configuration tab."""
        st.header("⚙️ QC Tests Configuration")
        
        if self.qc_tests.empty:
            st.warning("No QC tests data available.")
            return
        
        # Display QC tests overview
        st.subheader("Available QC Tests")
        st.write(f"**Total QC tests configured:** {len(self.qc_tests)}")
        
        # QC tests selection
        st.subheader("Select QC Test")
        
        # Prepare QC tests dataframe for selection
        display_tests = self.qc_tests.copy()
        
        # Add formatted display columns
        display_tests['Priority_Label'] = display_tests['priority'].astype(str)
        display_tests['Test_Name'] = display_tests.apply(
            lambda row: row.get('outcome_name', row['outcome_id']), axis=1
        )
        
        # Select columns for display
        display_columns = [
            'outcome_id', 'Test_Name', 'Priority_Label',
            'action_required', 'description'
        ]
        
        # Ensure all columns exist
        for col in display_columns:
            if col not in display_tests.columns:
                display_tests[col] = 'N/A'
        
        # Sort by priority (highest first)
        display_tests = display_tests.sort_values('priority', ascending=False)
        
        # Create display dataframe
        selection_df = display_tests[display_columns].copy()
        selection_df.columns = [
            'Outcome ID', 'Test Name', 'Priority', 'Action Required',
            'Description'
        ]
        
        # Display selectable dataframe
        selected_rows = st.dataframe(
            selection_df,
            use_container_width=True,
            hide_index=True,
            on_select="rerun",
            selection_mode="single-row",
            key="qc_tests_selection"
        )
        
        # Get selected test
        if selected_rows['selection']['rows']:
            selected_idx = selected_rows['selection']['rows'][0]
            selected_test = display_tests.iloc[selected_idx]
        else:
            # Default to first test if none selected
            selected_test = display_tests.iloc[0]
            st.info("👆 Select a QC test from the table above to view details.")
        
        # Display test details
        st.subheader("Test Details")
        st.write(f"**Outcome ID:** {selected_test['outcome_id']}")
        outcome_name = selected_test.get('outcome_name', 'N/A')
        st.write(f"**Name:** {outcome_name}")
        st.write(f"**Priority:** {selected_test['priority']}")
        description = selected_test.get('description', 'N/A')
        st.write(f"**Description:** {description}")
        action = selected_test['action_required']
        st.write(f"**Action Required:** {action}")
        conditions = selected_test['rule_conditions']
        st.write(f"**Rule Conditions:** {conditions}")
        
        # Related QC Rules Table
        st.subheader("Related QC Rules")
        
        if self.qc_rules.empty:
            st.warning("No QC rules data available.")
            return
        
        # Parse rule conditions to find related rules
        conditions = selected_test['rule_conditions']
        
        if pd.notna(conditions) and isinstance(conditions, str):
            if conditions == 'no_failed_rules':
                st.info("This test passes when no rules fail. "
                        "Showing all QC rules:")
                # Show all rules in a table
                rules_table_data = []
                for _, rule in self.qc_rules.iterrows():
                    rules_table_data.append({
                        'Rule ID': rule.get('rule_id', 'Unknown'),
                        'Species': rule.get('species', 'N/A'),
                        'Assembly Type': rule.get('assembly_type', 'N/A'),
                        'Software': rule.get('software', 'N/A'),
                        'Field': rule.get('field', 'N/A'),
                        'Operator': rule.get('operator', 'N/A'),
                        'Value': rule.get('value', 'N/A'),
                        'Special Field': rule.get('special_field', 'N/A')
                    })
                
                rules_df = pd.DataFrame(rules_table_data)
                st.dataframe(
                    rules_df,
                    use_container_width=True,
                    hide_index=True
                )
                
            elif conditions.startswith('failed_rules_contain:'):
                # Extract rule IDs and show them in a table
                condition_part = conditions.replace(
                    'failed_rules_contain:', ''
                )
                rule_ids = [
                    rule.strip() for rule in condition_part.split(',')
                ]
                
                num_rules = len(rule_ids)
                st.info(f"This test triggers when any of these "
                        f"{num_rules} rules fail:")
                
                # Create table with matching rules
                rules_table_data = []
                for rule_id in rule_ids:
                    matching_rules = self.qc_rules[
                        self.qc_rules['rule_id'] == rule_id
                    ]
                    
                    if not matching_rules.empty:
                        rule = matching_rules.iloc[0]
                        rules_table_data.append({
                            'Rule ID': rule_id,
                            'Species': rule.get('species', 'N/A'),
                            'Assembly Type': rule.get('assembly_type', 'N/A'),
                            'Software': rule.get('software', 'N/A'),
                            'Field': rule.get('field', 'N/A'),
                            'Operator': rule.get('operator', 'N/A'),
                            'Value': rule.get('value', 'N/A'),
                            'Special Field': rule.get('special_field', 'N/A')
                        })
                    else:
                        rules_table_data.append({
                            'Rule ID': rule_id,
                            'Species': 'Rule not found',
                            'Assembly Type': '-',
                            'Software': '-',
                            'Field': '-',
                            'Operator': '-',
                            'Value': '-',
                            'Special Field': '-'
                        })
                
                if rules_table_data:
                    rules_df = pd.DataFrame(rules_table_data)
                    st.dataframe(
                        rules_df,
                        use_container_width=True,
                        hide_index=True
                    )
                else:
                    st.warning("No matching rules found.")
            else:
                st.warning("Rule condition format not recognized.")
                st.code(conditions)
        else:
            st.warning("No rule conditions specified for this test.")

    def render_warnings_tab(self):
        """Render the warnings tab showing processing warnings and issues."""
        st.header("⚠️ Processing Warnings")
        
        if self.warnings is None or self.warnings.empty:
            st.info("No warnings file found or no warnings generated "
                    "during processing.")
            
            # Show information about warnings output
            warnings_path = self.config['app']['input'].get('warnings')
            if warnings_path:
                st.write(f"**Expected warnings file:** `{warnings_path}`")
                st.write("Warnings will be saved here during the next "
                         "uQCme processing run.")
            else:
                st.write("No warnings input path configured in config.yaml")
            return
        
        # Display summary statistics
        st.subheader("📊 Warnings Summary")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_warnings = len(self.warnings)
            st.metric("Total Warnings", total_warnings)
            # Add a divider
            st.markdown("---")

        with col2:
            warning_types = self.warnings['warning_type'].nunique()
            st.metric("Warning Types", warning_types)
        
        with col3:
            # Get most recent warning timestamp if available
            if 'timestamp' in self.warnings.columns:
                latest_warning = self.warnings['timestamp'].max()
                formatted_date = (
                    latest_warning.split('T')[0]
                    if 'T' in str(latest_warning)
                    else str(latest_warning)
                )
                st.metric("Latest Warning", formatted_date)
        
        # Filter by warning type
        st.subheader("🔍 Filter Warnings")
        
        col1, col2 = st.columns(2)
        
        with col1:
            warning_types = (
                ['All'] +
                sorted(self.warnings['warning_type'].unique().tolist())
            )
            selected_type = st.selectbox(
                "Warning Type",
                warning_types,
                key="warnings_type_filter"
            )
        
        with col2:
            # Search in warning messages
            search_term = st.text_input(
                "Search in messages",
                placeholder="Enter search term...",
                key="warnings_search"
            )
        
        # Apply filters
        filtered_warnings = self.warnings.copy()
        
        if selected_type != 'All':
            filtered_warnings = filtered_warnings[
                filtered_warnings['warning_type'] == selected_type
            ]
        
        if search_term:
            filtered_warnings = filtered_warnings[
                filtered_warnings['warning_message'].str.contains(
                    search_term, case=False, na=False
                )
            ]
        
        # Display warnings table
        st.subheader("📋 Warnings Details")
        
        if filtered_warnings.empty:
            st.info("No warnings match the current filters.")
        else:
            st.write(f"Showing {len(filtered_warnings)} of "
                     f"{len(self.warnings)} warnings")
            
            # Format warnings for display
            display_warnings = filtered_warnings.copy()
            
            # Format timestamp if available
            if 'timestamp' in display_warnings.columns:
                display_warnings['timestamp'] = (
                    pd.to_datetime(display_warnings['timestamp'])
                    .dt.strftime('%Y-%m-%d %H:%M:%S')
                )
            
            # Rename columns for better display
            column_mapping = {
                'warning_type': 'Type',
                'warning_message': 'Message',
                'timestamp': 'Timestamp'
            }
            
            display_warnings = display_warnings.rename(columns=column_mapping)
            
            # Display as a dataframe with styling
            st.dataframe(
                display_warnings,
                use_container_width=True,
                hide_index=True,
                column_config={
                    'Type': st.column_config.TextColumn(
                        'Type', width="small"
                    ),
                    'Message': st.column_config.TextColumn(
                        'Message', width="large"
                    ),
                    'Timestamp': st.column_config.TextColumn(
                        'Timestamp', width="medium"
                    )
                }
            )
            
            # Show warning type breakdown
            if len(filtered_warnings) > 1:
                st.subheader("📈 Warning Type Distribution")
                warning_counts = (
                    filtered_warnings['warning_type'].value_counts()
                )
                
                for warning_type, count in warning_counts.items():
                    percentage = (count / len(filtered_warnings)) * 100
                    st.write(f"**{warning_type}:** {count} warnings "
                             f"({percentage:.1f}%)")

    def run(self):
        """Run the Streamlit application."""
        # Setup page
        self.setup_page()
        
        # Load data
        self.load_data()
        
        # Render header (without metrics now)
        self.render_header()
        
        # Get filtered data (this will also render sidebar metrics)
        filtered_data = self.render_sidebar_filters()
        
        # Main content tabs
        tabs = st.tabs([
            "📊 Data Preview",
            "📈 Overview",
            "🔍 Quality Metrics",
            "🔬 Sample Details",
            "⚙️ QC Tests",
            "⚠️ Warnings"
        ])
        
        with tabs[0]:
            self.render_data_tab(filtered_data)
        
        with tabs[1]:
            self.render_overview_tab(filtered_data)
        
        with tabs[2]:
            self.render_quality_metrics_tab(filtered_data)
        
        with tabs[3]:
            self.render_sample_details_tab(filtered_data)
        
        with tabs[4]:
            self.render_qc_tests_tab()
        
        with tabs[5]:
            self.render_warnings_tab()


def main():
    """Main entry point for the Streamlit app."""
    # Configuration file path
    config_path = "config.yaml"
    
    # Check if config file exists
    if not Path(config_path).exists():
        st.error(f"Configuration file '{config_path}' not found!")
        st.stop()
    
    # Initialize and run dashboard
    dashboard = QCDashboard(config_path)
    dashboard.run()


if __name__ == "__main__":
    main()
